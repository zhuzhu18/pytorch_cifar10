import argparse
import torch

gpus = int(torch.cuda.device_count())
parser = argparse.ArgumentParser(description='PyTorch Training', conflict_handler='resolve')

# ------------------ models / network architectures ------------------
parser.add_argument('--arch', '-a', metavar='ARCH',
                    help='model architecture. ')

# ----------------------- global envs ---------------------------------
parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',
                    help='number of data loading workers (default: 4)')
parser.add_argument('--print-freq', '-f', default=10, type=int, metavar='N',
                    help='print frequency (default: 10)')
parser.add_argument('--gpus', '-g', default=gpus, type=int,
                    help='how many gpus will be used')

# ------------------ resume / pretrained / evaluation ------------------
parser.add_argument('--epochs', default=90, type=int, metavar='N', help='number of total epochs to run')
parser.add_argument('--start-epoch', default=0, type=int, metavar='N', help='manual epoch number (scripts on restarts)')
parser.add_argument('--resume', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')
parser.add_argument('--pretrained', dest='pretrained', action='store_true', help='use pre-trained model')
parser.add_argument('-e', '--evaluated', dest='evaluate', action='store_true', help='evaluate model on validation set')

# ------------------------ train hyper parameters -----------------------
parser.add_argument('-b', '--batch-size', default=256, type=int, metavar='N', help='mini-batch size (default: 256)')
parser.add_argument('--lr', '--learning-rate', default=0.1, type=float, metavar='LR', help='initial learning rate')
parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')
parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float, metavar='W',
                    help='weight decay (default: 1e-4)')

# ------------------------- distributed training --------------------------
parser.add_argument('-d', '--distributed-processes', default=1, type=int, help='number of distributed processes')
parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,
                    help='url used to set up distributed training')
parser.add_argument('--dist-backend', default='gloo', type=str, help='distributed backend')
